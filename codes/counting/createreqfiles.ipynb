{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import pathlib\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uttspkdict(FOLDER_PATH):\n",
    "    spkrlist = os.listdir(FOLDER_PATH)\n",
    "    spkrlist.sort()\n",
    "    uttspk = {}\n",
    "    for a in range(len(spkrlist)):\n",
    "        uttspk[spkrlist[a]] = [x for x in os.listdir(FOLDER_PATH+'/'+str(spkrlist[a])) if x.endswith(\"normal.wav\")]\n",
    "    return uttspk\n",
    "\n",
    "def uttspkdict2(FOLDER_PATH):\n",
    "    metadata = pd.read_csv('/home/oem/Desktop/DiCOVA/DiCOVA_Track_2_Release/metadata.csv')\n",
    "    spkrlist = list(metadata['ID'])\n",
    "    spkrlist.sort()\n",
    "    uttspk = {}\n",
    "    for a in range(len(spkrlist)):\n",
    "        uttspk[spkrlist[a]] = str(spkrlist[a])+\"-counting-normal.wav\"\n",
    "    return uttspk\n",
    "\n",
    "def writeuttspk(TEXT_PATH,dictionary,mode):\n",
    "    d_keys = dictionary.keys()\n",
    "    newlines = []\n",
    "    for spkr in d_keys:\n",
    "        for utt in dictionary[spkr]:\n",
    "            newline = spkr+'-'+utt + ' ' + spkr        \n",
    "            newlines.append(newline)\n",
    "    if (mode == 'new'):\n",
    "        with open(TEXT_PATH,'w') as f:\n",
    "            f.write(\"\\n\".join(newlines))\n",
    "    elif (mode == 'append'):\n",
    "        with open(TEXT_PATH,'a') as f:\n",
    "            f.write(\"\\n\")\n",
    "            f.write(\"\\n\".join(newlines))\n",
    "    else:\n",
    "        raise ValueError('Mode Not supported')\n",
    "    return \n",
    "\n",
    "def writeuttspk2(TEXT_PATH,dictionary,mode):\n",
    "    d_keys = dictionary.keys()\n",
    "    newlines = []\n",
    "    for spkr in d_keys:\n",
    "        utt = dictionary[spkr]\n",
    "        newline = utt + ' ' + spkr        \n",
    "        newlines.append(newline)\n",
    "    if (mode == 'new'):\n",
    "        with open(TEXT_PATH,'w') as f:\n",
    "            f.write(\"\\n\".join(newlines))\n",
    "    elif (mode == 'append'):\n",
    "        with open(TEXT_PATH,'a') as f:\n",
    "            f.write(\"\\n\")\n",
    "            f.write(\"\\n\".join(newlines))\n",
    "    else:\n",
    "        raise ValueError('Mode Not supported')\n",
    "    return \n",
    "\n",
    "\n",
    "def getwavpath(FOLDER_PATH):\n",
    "    my_list = list(pathlib.Path(FOLDER_PATH).glob('*normal.wav'))\n",
    "    my_list = [x.as_posix() for x in my_list]\n",
    "    my_list.sort()\n",
    "    return my_list\n",
    "\n",
    "def gettext(wavpath,asr,mode):\n",
    "    if(asr == 'aspire'):\n",
    "        if (mode == 'convert'):\n",
    "            text = \"/usr/bin/sox -t wav \" + wavpath + \" -c 1 -b 16 -r 8000 -t wav - |\"\n",
    "        elif(mode == 'direct'):\n",
    "            text = wavpath\n",
    "    elif(asr == 'timit'):\n",
    "        if (mode == 'convert'):\n",
    "            text = \"/home/oem/Desktop/kaldi/egs/timit/s5/../../../tools/sph2pipe_v2.5/sph2pipe -f wav \" + wavpath + \" |\"\n",
    "        elif(mode == 'direct'):\n",
    "            text = wavpath\n",
    "    return text\n",
    "\n",
    "def writescp(spkr,utt,text,dictionary,TEXT_PATH,mode):\n",
    "    d_keys = dictionary.keys()\n",
    "    newlines = []\n",
    "    newline = spkr+'-'+utt + ' ' + text        \n",
    "    newlines.append(newline)\n",
    "    if (mode == 'new'):\n",
    "        with open(TEXT_PATH,'w') as f:\n",
    "            f.write(\"\\n\".join(newlines))\n",
    "    elif (mode == 'append'):\n",
    "        with open(TEXT_PATH,'a') as f:\n",
    "            f.write(\"\\n\")\n",
    "            f.write(\"\\n\".join(newlines))\n",
    "    else:\n",
    "        raise ValueError('Mode Not supported')\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get utt2sp and wav.scp files for timit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run this to get utt2spk file for timit\n",
    "\"\"\"\n",
    "\n",
    "TEXT_PATH = '/home/oem/Desktop/asrworkdir/utt2spk.txt'\n",
    "FOLDER_PATH = \"/home/oem/Desktop/asrworkdir/data/test/dr\"\n",
    "\n",
    "for i in range(1,8):\n",
    "    my_dict = uttspkdict(FOLDER_PATH+str(i))\n",
    "    if i == 1:\n",
    "        writeuttspk(TEXT_PATH,my_dict,'new')\n",
    "    else:\n",
    "        writeuttspk(TEXT_PATH,my_dict,'append')\n",
    "\n",
    "        \n",
    "\"\"\"\n",
    "Run this to get the wavscp file for timit\n",
    "\"\"\"\n",
    "\n",
    "SCP_PATH = '/home/oem/Desktop/asrworkdir/wavscp.txt'\n",
    "FOLDER_PATH = \"/home/oem/Desktop/asrworkdir/data/test/dr\"\n",
    "\n",
    "for i in range(1,8):\n",
    "    my_dict = uttspkdict(FOLDER_PATH+str(i))\n",
    "    spkrlist = os.listdir(FOLDER_PATH+str(i))\n",
    "    spkrlist.sort()\n",
    "    for k in range(len(spkrlist)):\n",
    "        spkr = spkrlist[k]\n",
    "        utt = [x for x in os.listdir(FOLDER_PATH+str(i)+\"/\"+spkrlist[k]) if x.endswith(\".wav\")]\n",
    "        utt.sort()\n",
    "        wavpathlist = getwavpath(FOLDER_PATH+str(i)+\"/\"+spkrlist[k])\n",
    "        for j in range(len(wavpathlist)):\n",
    "            txt = gettext(wavpathlist[j],'timit','convert')\n",
    "            if(i==1 and k==0 and j==0):\n",
    "                writescp(spkr,utt[j],txt,my_dict,SCP_PATH,'new')           \n",
    "            else:\n",
    "                writescp(spkr,utt[j],txt,my_dict,SCP_PATH,'append')           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create utt2spk and wav.scp files for aspire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "FOLDER_PATH = \"/home/oem/Desktop/DiCOVA/Coswara/counting-normal\"\n",
    "sub = [ f.path for f in os.scandir(FOLDER_PATH)]\n",
    "sub.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run this to get utt2spk file for aspire\n",
    "\"\"\"\n",
    "\n",
    "TEXT_PATH = 'utt2spk'\n",
    "FOLDER_PATH = \"/home/oem/Desktop/DiCOVA/Coswara/counting-normal\"\n",
    "my_dict = uttspkdict2(FOLDER_PATH)\n",
    "writeuttspk2(TEXT_PATH,my_dict,'append')          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run this to get the wavscp file for aspire\n",
    "\"\"\"\n",
    "SCP_PATH = '/home/oem/Desktop/DiCOVA/Coswara/wav.scp'\n",
    "wavpathlist = []\n",
    "my_dict = uttspkdict2(FOLDER_PATH)\n",
    "metadata = pd.read_csv('/home/oem/Desktop/DiCOVA/DiCOVA_Track_2_Release/metadata.csv')\n",
    "spkrlist = list(metadata['ID'])\n",
    "spkrlist.sort()\n",
    "for k in range(len(spkrlist)):\n",
    "    spkr = spkrlist[k]\n",
    "    utt = \"counting-normal.wav\"\n",
    "    print(utt)\n",
    "    print(sub[k])\n",
    "    wavpathlist.append(sub[k])\n",
    "    txt = gettext(wavpathlist[k],'aspire','convert')\n",
    "    if(k==0):\n",
    "        writescp(spkr,utt,txt,my_dict,SCP_PATH,'new')           \n",
    "    else:\n",
    "        writescp(spkr,utt,txt,my_dict,SCP_PATH,'append') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format the posteriors files suitable to the next code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/oem/Desktop/DiCOVA/posteriors/combined/post4.txt\") as f:\n",
    "    lines = [line.rstrip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "Post = \"/home/oem/Desktop/DiCOVA/posteriors/\"\n",
    "Post_dir = Post+\"counting-normal/\"\n",
    "\n",
    "if os.path.isdir(folder):\n",
    "    print(\"Exists\")\n",
    "else:\n",
    "    print(\"Doesn't exist\")\n",
    "    os.mkdir(Post_dir)\n",
    "\n",
    "print(len(lines))\n",
    "for i in range(len(lines)):\n",
    "    x = lines[i]\n",
    "    y = x[:25]+\"post\"\n",
    "    with open(Post_dir+y,'a') as f:\n",
    "        z = x\n",
    "        a = z.replace(\" [\",\",[\")\n",
    "        f.write(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Posterior matrices for each utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findphoneindexprob(filename,phone_index):\n",
    "    f0 = open(filename,'r')\n",
    "    array = f0.read().split(',')\n",
    "    arr_indexprob=[]\n",
    "    for i in range (1,len(array)):\n",
    "        s0 = array[i]\n",
    "        if  ' '+str(phone_index) + ' ' in s0:\n",
    "            k=0\n",
    "            start = ' '+str(phone_index)+' '\n",
    "            s = array[i]\n",
    "            p = s.find(start)+len(start)\n",
    "            for space in s[p:]:\n",
    "                if (space == ' '):\n",
    "                    break\n",
    "                k+=1\n",
    "            arr_indexprob += [float(s[s.find(start)+len(start):s.find(start)+len(start)+k])]\n",
    "\n",
    "        else:\n",
    "            arr_indexprob += [0.0]\n",
    "    return arr_indexprob\n",
    "\n",
    "def findphoneprob(filename,phone):\n",
    "    with open(\"phonemap.txt\", 'r') as document:\n",
    "        phonedict = {}\n",
    "        for line in document:\n",
    "            line = line.split()\n",
    "            phonedict[line[0]] = line[1:]\n",
    "    arr_phoneprob = np.zeros(len(findphoneindexprob(filename,200))) #200 is an arbitrary non phone_index\n",
    "    for i in phonedict[phone]:\n",
    "        arr_phoneprob = np.add(findphoneindexprob(filename,i),arr_phoneprob)\n",
    "    return arr_phoneprob\n",
    "\n",
    "def sentenceprob(filename):\n",
    "    f = open(\"phonenames.txt\",'r')\n",
    "    phonenamearray = f.read().split(',')\n",
    "    y = []\n",
    "    for phone in phonenamearray:\n",
    "        y += [findphoneprob(filename,phone)]\n",
    "    y = np.array(y)    \n",
    "    return y.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the MFCC files in npy format from the scp file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaldiio\n",
    "import numpy as np\n",
    "PARENT_DIR = \"/home/oem/Desktop/DiCOVA\"\n",
    "FOLDER_PATH = \"/home/oem/Desktop/DiCOVA/Coswara/counting-normal\"\n",
    "with open(FOLDER_PATH+\"/feats.scp\",'r') as f:\n",
    "    for line in f:\n",
    "        (key,rxfile) = line.split(' ')\n",
    "        mfcc = kaldiio.load_mat(rxfile)\n",
    "        np.save(PARENT_DIR+\"/feats/mfcc/\"+key,mfcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the First Order statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fstat(spkr,output_loc,mfcc_data,postprob_data,phoneclass,threshold,start,shift,framelength):\n",
    "    for key in phoneclass:\n",
    "        while ((start+framelength)<=len(mfcc_data)):\n",
    "            mfcc = mfcc_data[start:(start+framelength)]\n",
    "            postprob = postprob_data[start:(start+framelength)]\n",
    "            postprob1 = postprob[:,phoneclass[key]]\n",
    "            if(np.sum(np.sum(postprob1,axis=0)) > threshold):\n",
    "                phonesum = np.sum(postprob1,axis = 0)\n",
    "                for k in range(0,len(phonesum)):\n",
    "                    if (phonesum[k] == 0):\n",
    "                        phonesum[k] = 1e-8\n",
    "                norm = np.divide(postprob1,phonesum)\n",
    "                vector1 = (np.dot(norm.T,mfcc))\n",
    "                vector = vector1.flatten()\n",
    "                np.save(output_loc+key+'/'+spkr+'_'+str(start)+'.npy',vector)                    \n",
    "\n",
    "            start+=shift    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "phoneclass = {'full':[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38]}\n",
    "mfcc_dir = '/home/oem/Desktop/DiCOVA/feats/mfccnew/'\n",
    "mfcc = os.listdir(mfcc_dir)\n",
    "mfcc.sort()\n",
    "post_dir = '/home/oem/Desktop/DiCOVA/posteriors/counting-normal/'\n",
    "post = os.listdir(post_dir)\n",
    "post.sort()\n",
    "output_loc = '/home/oem/Desktop/DiCOVA/stats/' \n",
    "for i in range(len(mfcc)):\n",
    "        mfcc_data = np.load(mfcc_dir+mfcc[i])\n",
    "        postprob_data = sentenceprob(post_dir+post[i])\n",
    "        threshold = 0\n",
    "        start = 0\n",
    "        shift = len(mfcc_data)\n",
    "        framelength = len(mfcc_data)\n",
    "        spkr = post[i][:-5]\n",
    "        fstat(spkr,output_loc,mfcc_data,postprob_data,phoneclass,threshold,start,shift,framelength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_loc = '/home/oem/Desktop/DiCOVA/stats/' \n",
    "x = np.load('/home/oem/Desktop/DiCOVA/stats/augmented/AATVTZch-counting-normal_10.npy')\n",
    "np.shape(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply PCA to the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('AANHmWlD', 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv('/home/oem/Desktop/DiCOVA/DiCOVA_Track_2_Release/metadata.csv')\n",
    "metadata = metadata.replace('p',1)\n",
    "md = metadata.replace('n',0)\n",
    "\n",
    "fstats_folder = '/home/oem/Desktop/DiCOVA/stats/augmented/'\n",
    "fstats = os.listdir(fstats_folder)\n",
    "fstats.sort()\n",
    "x = np.fromfile(fstats_folder+fstats[1])\n",
    "md['ID'][0],md['Covid_status'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fstats_folder = '/home/oem/Desktop/DiCOVA/stats/full/'\n",
    "x_folder = '/home/oem/Desktop/DiCOVA/'\n",
    "fstats = os.listdir(fstats_folder)\n",
    "fstats.sort()\n",
    "for i in range(1,6):\n",
    "    file = open('/home/oem/Desktop/DiCOVA/DiCOVA_Track_2_Release/LISTS/val_fold_'+str(i)+'.txt', 'r')\n",
    "    ids = file.readlines()\n",
    "    ids = [line.strip() for line in ids]\n",
    "    ids.sort()\n",
    "    for j in range(len(fstats)):\n",
    "        fstat = fstats[j]\n",
    "        ID = fstat[:8]\n",
    "        for k in range(len(ids)):\n",
    "            if(ID == ids[k]):\n",
    "                fn = list(md['ID'])\n",
    "                ind = fn.index(ID)\n",
    "                label = md['Covid_status'][ind]\n",
    "                text = fstats_folder+fstat+\" \"+str(label)\n",
    "                with open(x_folder+\"val_fold_\"+str(i)+\".list\",'a') as listfile:\n",
    "                    listfile.write(text+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "featdim =1560\n",
    "def load_input(file_path):\n",
    "    with open(file_path) as f:  \n",
    "        line = f.readline()\n",
    "        cnt = 1\n",
    "        tr = np.empty(shape=[0,featdim])\n",
    "        covid_trgt = []\n",
    "        while line:\n",
    "            [path,rem] = line.split()\n",
    "            covid = float(rem)\n",
    "            data_array = np.load(path)\n",
    "            da = np.reshape(data_array,(1,-1))\n",
    "            covid_trgt.append(height)\n",
    "            tr = np.append(tr,da,axis=0)\n",
    "            line = f.readline()\n",
    "            cnt+=1\n",
    "        print(\"train shape :\",np.shape(tr), \"targets shape :\", np.shape(covid_trgt))\n",
    "    return [tr,covid_trgt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape : (15369, 1560) targets shape : (15369,)\n",
      "train shape : (15652, 1560) targets shape : (15652,)\n",
      "train shape : (15734, 1560) targets shape : (15734,)\n",
      "train shape : (15748, 1560) targets shape : (15748,)\n",
      "train shape : (15789, 1560) targets shape : (15789,)\n",
      "train shape : (207, 1560) targets shape : (207,)\n",
      "train shape : (207, 1560) targets shape : (207,)\n",
      "train shape : (207, 1560) targets shape : (207,)\n",
      "train shape : (207, 1560) targets shape : (207,)\n",
      "train shape : (207, 1560) targets shape : (207,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "tr1_X,tr1_Y = load_input(\"/home/oem/Desktop/DiCOVA/train_fold_1.list\")\n",
    "tr2_X,tr2_Y = load_input(\"/home/oem/Desktop/DiCOVA/train_fold_2.list\") \n",
    "tr3_X,tr3_Y = load_input(\"/home/oem/Desktop/DiCOVA/train_fold_3.list\") \n",
    "tr4_X,tr4_Y = load_input(\"/home/oem/Desktop/DiCOVA/train_fold_4.list\") \n",
    "tr5_X,tr5_Y = load_input(\"/home/oem/Desktop/DiCOVA/train_fold_5.list\") \n",
    "\n",
    "val1_X,val1_Y = load_input(\"/home/oem/Desktop/DiCOVA/val_fold_1.list\")\n",
    "val2_X,val2_Y = load_input(\"/home/oem/Desktop/DiCOVA/val_fold_2.list\")\n",
    "val3_X,val3_Y = load_input(\"/home/oem/Desktop/DiCOVA/val_fold_3.list\")\n",
    "val4_X,val4_Y = load_input(\"/home/oem/Desktop/DiCOVA/val_fold_4.list\")\n",
    "val5_X,val5_Y = load_input(\"/home/oem/Desktop/DiCOVA/val_fold_5.list\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()# Fit on training set only.\n",
    "pca = PCA(300)\n",
    "\n",
    "scaler.fit(tr1_X)\n",
    "tr1_X = scaler.transform(tr1_X)\n",
    "val1_X = scaler.transform(val1_X)\n",
    "pca.fit(tr1_X)\n",
    "tr1_X = pca.transform(tr1_X)\n",
    "val1_X = pca.transform(val1_X)\n",
    "\n",
    "scaler.fit(tr2_X)\n",
    "tr2_X = scaler.transform(tr2_X)\n",
    "val2_X = scaler.transform(val2_X)\n",
    "pca.fit(tr2_X)\n",
    "tr2_X = pca.transform(tr2_X)\n",
    "val2_X = pca.transform(val2_X)\n",
    "\n",
    "scaler.fit(tr3_X)\n",
    "tr3_X = scaler.transform(tr3_X)\n",
    "val3_X = scaler.transform(val3_X)\n",
    "pca.fit(tr3_X)\n",
    "tr3_X = pca.transform(tr3_X)\n",
    "val3_X = pca.transform(val3_X)\n",
    "\n",
    "scaler.fit(tr4_X)\n",
    "tr4_X = scaler.transform(tr4_X)\n",
    "val4_X = scaler.transform(val4_X)\n",
    "pca.fit(tr4_X)\n",
    "tr4_X = pca.transform(tr4_X)\n",
    "val4_X = pca.transform(val4_X)\n",
    "\n",
    "scaler.fit(tr5_X)\n",
    "tr5_X = scaler.transform(tr5_X)\n",
    "val5_X = scaler.transform(val5_X)\n",
    "pca.fit(tr5_X)\n",
    "tr5_X = pca.transform(tr5_X)\n",
    "val5_X = pca.transform(val5_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 300)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 [[186   0]\n",
      " [ 21   0]]\n",
      "0.001 [[186   0]\n",
      " [ 21   0]]\n",
      "0.001 [[186   0]\n",
      " [ 21   0]]\n",
      "0.001 [[186   0]\n",
      " [ 21   0]]\n",
      "0.001 [[186   0]\n",
      " [ 21   0]]\n",
      "0.01 [[186   0]\n",
      " [ 21   0]]\n",
      "0.01 [[186   0]\n",
      " [ 21   0]]\n",
      "0.01 [[186   0]\n",
      " [ 21   0]]\n",
      "0.01 [[186   0]\n",
      " [ 21   0]]\n",
      "0.01 [[186   0]\n",
      " [ 21   0]]\n",
      "0.1 [[186   0]\n",
      " [ 21   0]]\n",
      "0.1 [[186   0]\n",
      " [ 21   0]]\n",
      "0.1 [[186   0]\n",
      " [ 21   0]]\n",
      "0.1 [[186   0]\n",
      " [ 21   0]]\n",
      "0.1 [[186   0]\n",
      " [ 21   0]]\n",
      "1 [[186   0]\n",
      " [ 21   0]]\n",
      "1 [[186   0]\n",
      " [ 21   0]]\n",
      "1 [[186   0]\n",
      " [ 21   0]]\n",
      "1 [[186   0]\n",
      " [ 21   0]]\n",
      "1 [[186   0]\n",
      " [ 21   0]]\n",
      "10 [[186   0]\n",
      " [ 21   0]]\n",
      "10 [[186   0]\n",
      " [ 21   0]]\n",
      "10 [[186   0]\n",
      " [ 21   0]]\n",
      "10 [[186   0]\n",
      " [ 21   0]]\n",
      "10 [[186   0]\n",
      " [ 21   0]]\n",
      "100 [[186   0]\n",
      " [ 21   0]]\n",
      "100 [[186   0]\n",
      " [ 21   0]]\n",
      "100 [[186   0]\n",
      " [ 21   0]]\n",
      "100 [[186   0]\n",
      " [ 21   0]]\n",
      "100 [[186   0]\n",
      " [ 21   0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix as conf\n",
    "# clf = svm.LinearSVC(random_state = 0,tol=1e-5,dual=False,penalty='l2',max_iter = 10000,C = 10,class_weight = 'balanced')\n",
    "C = [0.001,0.01,0.1,1,10,100]\n",
    "for i in range(len(C)):\n",
    "    clf = svm.SVC(C = C[i])\n",
    "    clf.fit(tr1_X,tr1_Y)\n",
    "    acc1=clf.score(val1_X,val1_Y)\n",
    "    y_pred1 = clf.predict(val1_X)\n",
    "\n",
    "    clf.fit(tr2_X,tr2_Y)\n",
    "    acc2=clf.score(val2_X,val2_Y)\n",
    "    y_pred2 = clf.predict(val2_X)\n",
    "\n",
    "    clf.fit(tr3_X,tr3_Y)\n",
    "    acc3=clf.score(val3_X,val3_Y)\n",
    "    y_pred3 = clf.predict(val3_X)\n",
    "\n",
    "    clf.fit(tr4_X,tr4_Y)\n",
    "    acc4=clf.score(val4_X,val4_Y)\n",
    "    y_pred4 = clf.predict(val4_X)\n",
    "\n",
    "    clf.fit(tr5_X,tr5_Y)\n",
    "    acc5=clf.score(val5_X,val5_Y)\n",
    "    y_pred5 = clf.predict(val5_X)\n",
    "    \n",
    "    conf1 = conf(val1_Y,y_pred1)\n",
    "    conf2 = conf(val2_Y,y_pred2)\n",
    "    conf3 = conf(val3_Y,y_pred3)\n",
    "    conf4 = conf(val4_Y,y_pred4)\n",
    "    conf5 = conf(val5_Y,y_pred5)\n",
    "    \n",
    "    print(C[i],conf1)\n",
    "    print(C[i],conf2)\n",
    "    print(C[i],conf3)\n",
    "    print(C[i],conf4)\n",
    "    print(C[i],conf5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
